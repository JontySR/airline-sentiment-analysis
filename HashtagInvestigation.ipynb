{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HashtagInvestigation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3Cwx+YJ70+x3/AECDaftr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JontySR/airline-sentiment-analysis/blob/master/HashtagInvestigation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmXXf7BM5TM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "b6273ce9-0737-4758-e09a-686f37dedfd6"
      },
      "source": [
        "#HASHTAG ANALYSIS\n",
        "# 1. read in the tweets and isolate the hashtags from the text by checking if a token startswith #\n",
        "# 2. find out if there are any hashtags which are reused. What are they about? How common are they?#\n",
        "\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "paths = ['/content/american.csv','/content/virgin.csv','/content/united.csv','/content/southwest.csv','/content/us_airways.csv','/content/delta.csv']\n",
        "def list_popularity(items=hashes, count=10):\n",
        "    return {hash: count for hash, count in Counter(items).most_common(count)}\n",
        "def import_dataset(path):\n",
        "  return pd.read_csv(path,names=['tweet_ID','sentiment', 'sentiment_confidence', 'negative_reason','negative_reason_confidence','airline','airline_sentiment_gold','name','negative_reason_gold','retweets','text','coordinates','creation_time','location','timezone'])\n",
        "\n",
        "def find_hashes(dataset):\n",
        "  res = []\n",
        "  for row in dataset['text']:\n",
        "    res += [tag.strip('#') for tag in row.split() if tag.startswith('#') and len(tag) >1]\n",
        "  return res\n",
        "\n",
        "def analysis(path):\n",
        "  return list_popularity(find_hashes(import_dataset(path)))\n",
        "\n",
        "\n",
        "for path in paths:\n",
        "  print(analysis(path))\n",
        "\n",
        "#CONCLUSION:\n",
        "#The best airline coming out of the hashtag analysis is Virgin America\n",
        "#The worst airlines coming out of the hashtag analysis are United and US Airways due to the strength of their negative hashes\n",
        "#American Airlines: 83 Hashtags, strongest negative: #fail, strongest positive: thenewamerican"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'AmericanAirlines': 21, 'fail': 9, 'DFW': 8, 'customerservice': 7, 'filmcrew': 6, 'media': 6, 'AA2444': 4, 'thenewamerican': 4, 'frustrated': 4, 'neveragain': 4}\n",
            "{'CheapFlights': 4, 'FareCompare': 4, 'help': 4, 'virginamerica': 3, 'MiddleEast': 3, 'MoodlitMonday': 2, 'ScienceBehindTheExperience': 2, 'Oscars2015': 2, 'Oscars': 2, 'flight': 2}\n",
            "{'UnitedAirlines': 33, 'fail': 16, 'united': 15, 'customerservice': 12, 'unitedairlines': 10, 'United': 10, 'unfriendlyskies': 9, 'avgeek': 8, 'unitedsucks': 8, 'badservice': 7}\n",
            "{'DestinationDragons': 71, 'fail': 6, 'disappointed': 5, 'southwestairlines': 5, 'B737-700': 5, 'avgeek': 5, 'customerservice': 5, 'destinationdragons': 5, 'SWA': 4, 'notcool': 4}\n",
            "{'usairwaysfail': 25, 'USAirways': 15, 'fail': 14, 'usairways': 12, 'customerservice': 7, 'neveragain': 6, 'usairwayssucks': 6, 'disappointed': 5, 'nothappy': 4, 'badcustomerservice': 4}\n",
            "{'jetblue': 33, 'JetBlue': 8, 'flyingitforward': 7, 'travel': 6, 'Lufthansa': 6, 'fail': 6, 'JVMChat': 5, 'flyfi': 4, 'trueblue': 4, 'jfk': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTzt9Rn1AzHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "95149de0-2ae9-4147-dd8e-96327bb8b77f"
      },
      "source": [
        "#WHICH AIRLINE HAS THE WORST REPUTATION FOR EACH KIND OF COMPLAINT BASED OFF THE CSV DATA\n",
        "#PRIORITISE LATE\n",
        "\n",
        "def count_complaint(complaints):\n",
        "  return {complaint: count for complaint, count in Counter(complaints).most_common(12)}\n",
        "for path in paths:\n",
        "  print(path)\n",
        "  print(count_complaint(import_dataset(path)['negative_reason']))\n",
        "  \n",
        "#Takeaways:\n",
        "#Virgin is the least represented in the dataset however, it has relatively fewer complaints than the others\n",
        "#Delta rarely cancel flights compared to the other large airlines.\n",
        "#US Airways have more customer service issues than neutral or positive tweets about them which is rather alarming\n",
        "#American has far more complaints than it has positive or neutral tweets\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/american.csv\n",
            "{nan: 799, 'Customer Service Issue': 768, 'Late Flight': 249, 'Cancelled Flight': 246, \"Can't Tell\": 198, 'Lost Luggage': 149, 'Flight Booking Problems': 130, 'Bad Flight': 87, 'Flight Attendant Complaints': 87, 'longlines': 34, 'Damaged Luggage': 12}\n",
            "/content/virgin.csv\n",
            "{nan: 323, 'Customer Service Issue': 60, 'Flight Booking Problems': 28, \"Can't Tell\": 22, 'Bad Flight': 19, 'Cancelled Flight': 18, 'Late Flight': 17, 'Lost Luggage': 5, 'Flight Attendant Complaints': 5, 'Damaged Luggage': 4, 'longlines': 3}\n",
            "/content/united.csv\n",
            "{nan: 1189, 'Customer Service Issue': 681, 'Late Flight': 525, \"Can't Tell\": 379, 'Lost Luggage': 269, 'Bad Flight': 216, 'Cancelled Flight': 181, 'Flight Attendant Complaints': 168, 'Flight Booking Problems': 144, 'longlines': 48, 'Damaged Luggage': 22}\n",
            "/content/southwest.csv\n",
            "{nan: 1234, 'Customer Service Issue': 391, 'Cancelled Flight': 162, \"Can't Tell\": 159, 'Late Flight': 152, 'Bad Flight': 90, 'Lost Luggage': 90, 'Flight Booking Problems': 61, 'Flight Attendant Complaints': 38, 'longlines': 29, 'Damaged Luggage': 14}\n",
            "/content/us_airways.csv\n",
            "{'Customer Service Issue': 811, nan: 650, 'Late Flight': 453, \"Can't Tell\": 246, 'Cancelled Flight': 189, 'Lost Luggage': 154, 'Flight Attendant Complaints': 123, 'Flight Booking Problems': 122, 'Bad Flight': 104, 'longlines': 50, 'Damaged Luggage': 11}\n",
            "/content/delta.csv\n",
            "{nan: 1267, 'Late Flight': 269, 'Customer Service Issue': 199, \"Can't Tell\": 186, 'Bad Flight': 64, 'Flight Attendant Complaints': 60, 'Lost Luggage': 57, 'Cancelled Flight': 51, 'Flight Booking Problems': 44, 'longlines': 14, 'Damaged Luggage': 11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRaZf6KUFrJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "52bd4a8b-d542-4d2f-e037-fe6134501884"
      },
      "source": [
        "#FIND OUT IF ANY OF THE DAMAGED LUGGAGE INCIDENTS HAPPENED ON THE SAME UNITED FLIGHT\n",
        "dataset = import_dataset(paths[5]) #CHANGE BETWEEN 0 AND 5 TO SHOW DIFFERENT TWEETS\n",
        "\n",
        "for index, row in enumerate(dataset['negative_reason'], start=0):\n",
        "  if row == 'Damaged Luggage':\n",
        "    print(dataset['name'].loc[index], dataset['text'].loc[index], dataset['creation_time'].loc[index], dataset['location'].loc[index])\n",
        "    print('\\n')\n",
        "\n",
        "#VIRGIN AMERICA ONLY HAS ONE ACTUAL INCIDENT OF LUGGAGE BEING DAMAGED. THEY DON'T NEED TO IMPROVE THIS ASPECT OF THEIR SERVICE\n",
        "#3 OF THE TWEETS ARE FROM THE SAME USER ABOUT THE SAME INCIDENT\n",
        "#THE OTHER TWEET WAS ABOUT WORRYING IF ITEMS WERE GOING TO BE DAMAGED; NOT THAT THEY WERE.\n",
        "\n",
        "#AMERICAN AIR CUSTOMER SERVICES RESPONED TO A USER WHOSE BAG WAS DAMAGED AT STAMFORD CT TO RESOLVE THE ISSUE\n",
        "#DESPITE THIS BEING A NEGATIVE TWEET ACCORING TO ITS SENTIMENT, THE HASHTAG MAKES IT POSITIVE, HENCE THE IMPORTANCE OF HASHTAG ANALYSIS\n",
        "\n",
        "#AMERICAN AIR USER REPORTED THEIR LUGGAGE TO HAVE BEEN STOLEN BY BAGGAGE HANDLERS?\n",
        "#LIKE VIRGIN, THERE AREN'T ACTUALLY THAT MANY CASES OF DAMAGED LUGGAGE. NEARLY HALF OF THE TWEETS ABOUT THIS ISSUE ARE REPLIES.\n",
        "#COMPLAINTS THAT TABLET WAS DAMAGED IS MORE ON THE CUSTOMER STORING A FLAT DEVICE LIKE THAT AT THE TOP OF A SUITCASE.\n",
        "\n",
        "#UNITED DAMAGED LUGGAGE CASES ARE ALL ISOLATED INCIDENTS AT DIFFERENT LOCATIONS HOWEVER, THE TWEETS MOSTLY SAY THAT SOMETHING WAS INDEED DAMAGED.\n",
        "#AGAIN, THERE ARE SOME WHICH ARE CLASSED AS DAMAGED LUGGAGE YET NOTHING HAS DEFINITIVELY BEEN DAMAGED.\n",
        "\n",
        "#SOUTHWEST DOES NOT APPEAR TO RESPOND TO CUSTOMERS DIRECTLY EVEN IF THEY TAG THEM AND SHOW A PHOTO OF THE DAMAGE\n",
        "#SOME OF THE TWEETS ARE INCORRECTLY CLASSIFIED AS DAMAGED LUGGAGE ONCE AGAIN WHEN THEY'RE ACTUALLY ABOUT DAMAGE BEING PREVENTED\n",
        "\n",
        "#MOST OF THE US AIRWAYS TWEETS HAVE BEEN CORRECTLY CLASSIFIED. THERE ARE A FEW REPLIES WHICH CAN BE REMOVED WITH JONATHAN'S REPLY DESTROYER\n",
        "#SOME ARE ABOUT THE BAGGAGE COLLECTION SERVICE HAVING DELAYS WHICH ISN'T A DAMAGE PROBLEM BUT INSTEAD CUSTOMER SERVICE\n",
        "\n",
        "#JETBLUE CUSTOMER SERVICES ON TWITTER ARE INDEED RESPONSIVE IF A USER REPORTS STOLEN BAGS AS SHOWN IN JetBlue.JPG\n",
        "#THESE TWEETS SHOW A PROBLEM WITH NLP: PEOPLE USING 2 INSTEAD OF TWO"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DarthVada_R2D2 @JetBlue - Definitely no note from whoever stole from me. 23/02/2015 19:42 nan\n",
            "\n",
            "\n",
            "edgarsantana @JetBlue I just submitted feedback for you @gripeo. Not a good way 2 handle baggage or customers: http://t.co/F6COpX1Fvj 18/02/2015 17:26 ÃœT: 40.96513,-73.872957\n",
            "\n",
            "\n",
            "edgarsantana @JetBlue I had 2 fight 2 get a credit for the value of my bag but I got it. #skytrax #jetblue #corpgreed #nevertakeno http://t.co/6MBVJFlpBM 18/02/2015 16:05 ÃœT: 40.96513,-73.872957\n",
            "\n",
            "\n",
            "edgarsantana @JetBlue so why do you put this at the bottom of ur baggage report? For fun? #JetBlue @airlinequality #skytrax http://t.co/tU9JX2jaZN 18/02/2015 15:11 ÃœT: 40.96513,-73.872957\n",
            "\n",
            "\n",
            "edgarsantana @JetBlue u now have my gears grinding. The JFK baggage office told me I need to bring the bag back right now if not they will close my claim 18/02/2015 14:54 ÃœT: 40.96513,-73.872957\n",
            "\n",
            "\n",
            "edgarsantana @JetBlue U say our safety is our highest priority but that doesn't extend 2 our property? This is totally nuts. http://t.co/xZY7pHKFGR 18/02/2015 14:38 ÃœT: 40.96513,-73.872957\n",
            "\n",
            "\n",
            "edgarsantana @JetBlue glad u happy I have my bag but as a traveler I entrusted u w/ my property &amp; u return it damaged &amp; that's the best answer u have? 18/02/2015 14:33 ÃœT: 40.96513,-73.872957\n",
            "\n",
            "\n",
            "LisaPal @JetBlue but you guys should know that musicians are very sensitive about the safety of their instruments when flying. For good reason. 18/02/2015 09:58 New Orleans, LA\n",
            "\n",
            "\n",
            "michaelhakimkan @JetBlue ripped my suitcase. I then was yelled at with attitude from Geraldine, your employee at the baggage center.Worst airline= #jetblue 17/02/2015 20:30 nan\n",
            "\n",
            "\n",
            "ShiraJudah @JetBlue @KyleJudah new stroller. The travel credit doesn't help cover the cost of a new stroller. Your crew ruined it and therefore should 17/02/2015 11:48 Boston, MA\n",
            "\n",
            "\n",
            "ShiraJudah @JetBlue @KyleJudah I just spoke to the baggage claim center and they gave me travel credit but will not be responsible for the cost of a 17/02/2015 11:46 Boston, MA\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYR9LPysWhHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Take each emoji and give it a polarity modifier. If it appears in the text, add the modifier to the sentiment score.\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "import csv\n",
        "texts = []\n",
        "sentiments = []\n",
        "results = []\n",
        "def reset_score(score):\n",
        "  if score > 1:\n",
        "    return 1\n",
        "  if score < -1:\n",
        "    return -1\n",
        "  return score  \n",
        "def emoji_based_sentiment(tweets, combined, results):\n",
        "  with open('/content/textblobsentiments.csv','w') as file:\n",
        "    writer = csv.writer(file)\n",
        "    for tweet in tweets['text']:\n",
        "      score = TextBlob(tweet).sentiment[0]\n",
        "      oldscore = score\n",
        "      for record in combined:\n",
        "        if record[0] in tweet:\n",
        "          score += record[1]\n",
        "      score = reset_score(score)\n",
        "      writer.writerow((tweet, oldscore, score))\n",
        "\n",
        "emojis = ['â¤', 'â¤ï¸', 'â˜º', 'â˜ºï¸', 'ðŸ‘', 'ðŸ˜¡', 'ðŸ˜¢', 'âœˆ', 'ðŸ’œ', 'âœˆï¸', 'ðŸ’º', 'ðŸ·', 'ðŸ˜Š', 'ðŸ‘Œ', 'ðŸ˜', 'ðŸ’•', 'ðŸŒž', 'ðŸ˜ƒ', 'ðŸ˜­', 'ðŸ˜©', 'ðŸ˜Ž', 'ðŸ™‰', 'ðŸ˜', 'â„', 'â„ï¸', 'ðŸ‘', 'ðŸ˜‚', 'ðŸ’—', 'ðŸ¸', 'ðŸ˜’', 'ðŸ‘Ž', 'ðŸ˜€', 'ðŸ˜„', 'ðŸ˜˜', 'ðŸ‡ºðŸ‡¸', 'ðŸ‘¸', 'ðŸ‡¸', 'ðŸ‡º', 'ðŸ‡¬ðŸ‡§', 'ðŸŒ', 'ðŸ‡§', 'ðŸ‡¬', 'ðŸŽ€', 'ðŸ˜¥', 'ðŸ˜‰', 'ðŸ˜±', 'âœ¨', 'ðŸŽ‰', 'ðŸ™Œ', 'ðŸ’¤', 'ðŸ˜ž', 'â™¥', 'ðŸ‘‹', 'âœŒ', 'âœŒï¸', 'ðŸ™', 'ðŸ‘¿', 'ðŸ˜”', 'ðŸ™…', 'ðŸ†–', 'ðŸ’©', 'âœ”ï¸', 'âœ”', 'ðŸŒ´', 'âŒ', 'âœ…', 'ðŸ‘ ', 'ðŸ˜œ', 'ðŸ˜»', 'ðŸ˜•', 'ðŸ˜ˆ', 'ðŸ˜¤', 'ðŸ’ª', 'ðŸ˜«', 'ðŸ’”', 'ðŸ˜ª', 'ðŸ˜£', 'ðŸ˜¬', 'ðŸ’', 'ðŸ˜‹', 'ðŸ˜', 'ðŸ˜–', 'ðŸŒŸ', 'ðŸ“±', 'ðŸ»', 'ðŸ’–', 'ðŸ˜…', 'ðŸ’', 'â†”', 'â†”ï¸', 'ðŸš«', 'ðŸ˜·', 'â­', 'â—', 'ðŸŽµ', 'ðŸ´', 'â™¥ï¸', 'ðŸ˜†', 'ðŸ˜‘', 'ðŸ©', 'â¤´', 'â˜€', 'â˜€ï¸', 'ðŸ‘Š', 'ðŸ’¯', 'ðŸ˜ ', 'â˜•', 'ðŸ“²', 'ðŸ‘º', 'ðŸ™ˆ', 'ðŸ’˜', 'ðŸ’™', 'ðŸ‘‰', 'ðŸšª', 'ðŸ˜³', 'ðŸ˜µ', 'ðŸš¶', 'ðŸ”µ', 'ðŸ˜', 'ðŸ‘€', 'ðŸ…', 'ðŸ†˜', 'â›„', 'ðŸ˜“', 'ðŸŽ²', 'âŒš', 'ðŸ³', 'â¤µ', 'ðŸ˜®', 'ðŸ˜²', 'ðŸ˜¦', 'âž¡', 'âž¡ï¸']\n",
        "scores = [0.25,0.27,0.2,0.2,0.15,-0.2,-0.25,0.05,0.25,0.05,0.02,0.08,0.3,0.15,0.3,0.2,0.19,0.25,-0.3,-0.25,0.15,-0.1,0.27,-0.08,-0.08,0.1,0.05,0.18,0.06,-0.18,-0.2,0.28,0.25,0.16,0.05,0.03,0.00,0.00,0.00,0.05,0.00,0.00,0.04,-0.16,0.14,-0.19,0.09,0.13,0.13,-0.04,-0.21,0.22,0.06,0.07,0.07,0.09,-0.3,-0.14,-0.08,0.00,-0.3,0.2,0.2,0.11,-0.2,0.2,0.05,0.15,0.12,-0.16,-0.28,-0.25,0.15,-0.16,-0.2,0.03,-0.04,-0.07,0.00,0.16,0.04,-0.16,0.24,0.03,0.1,0.25,0.1,0.25,0.0,0.0,-0.1,-0.15,0.22,-0.06,0.05,0.02,0.06,-0.1,0.1,0.0,0.03,0.1,-0.01,0.17,-0.2,0.06,0.06,-0.1,0.05,-0.15,0.2,0.04,0.01,-0.05,-0.08,0.00,0.00,-0.09,-0.05,0.05,-0.14,0.04,-0.15,0.1,-0.1,0.1,0.01,0.05,0.0,0.1,0.05,-0.1,0.00,0.00]\n",
        "combined = list(zip(emojis, scores))\n",
        "\n",
        "tweets = pd.read_csv('/content/Tweets.csv')\n",
        "emoji_based_sentiment(tweets, combined, results)"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}