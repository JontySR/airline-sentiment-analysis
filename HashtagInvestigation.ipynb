{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HashtagInvestigation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3Cwx+YJ70+x3/AECDaftr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JontySR/airline-sentiment-analysis/blob/master/HashtagInvestigation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmXXf7BM5TM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "b6273ce9-0737-4758-e09a-686f37dedfd6"
      },
      "source": [
        "#HASHTAG ANALYSIS\n",
        "# 1. read in the tweets and isolate the hashtags from the text by checking if a token startswith #\n",
        "# 2. find out if there are any hashtags which are reused. What are they about? How common are they?#\n",
        "\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "paths = ['/content/american.csv','/content/virgin.csv','/content/united.csv','/content/southwest.csv','/content/us_airways.csv','/content/delta.csv']\n",
        "def list_popularity(items=hashes, count=10):\n",
        "    return {hash: count for hash, count in Counter(items).most_common(count)}\n",
        "def import_dataset(path):\n",
        "  return pd.read_csv(path,names=['tweet_ID','sentiment', 'sentiment_confidence', 'negative_reason','negative_reason_confidence','airline','airline_sentiment_gold','name','negative_reason_gold','retweets','text','coordinates','creation_time','location','timezone'])\n",
        "\n",
        "def find_hashes(dataset):\n",
        "  res = []\n",
        "  for row in dataset['text']:\n",
        "    res += [tag.strip('#') for tag in row.split() if tag.startswith('#') and len(tag) >1]\n",
        "  return res\n",
        "\n",
        "def analysis(path):\n",
        "  return list_popularity(find_hashes(import_dataset(path)))\n",
        "\n",
        "\n",
        "for path in paths:\n",
        "  print(analysis(path))\n",
        "\n",
        "#CONCLUSION:\n",
        "#The best airline coming out of the hashtag analysis is Virgin America\n",
        "#The worst airlines coming out of the hashtag analysis are United and US Airways due to the strength of their negative hashes\n",
        "#American Airlines: 83 Hashtags, strongest negative: #fail, strongest positive: thenewamerican"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'AmericanAirlines': 21, 'fail': 9, 'DFW': 8, 'customerservice': 7, 'filmcrew': 6, 'media': 6, 'AA2444': 4, 'thenewamerican': 4, 'frustrated': 4, 'neveragain': 4}\n",
            "{'CheapFlights': 4, 'FareCompare': 4, 'help': 4, 'virginamerica': 3, 'MiddleEast': 3, 'MoodlitMonday': 2, 'ScienceBehindTheExperience': 2, 'Oscars2015': 2, 'Oscars': 2, 'flight': 2}\n",
            "{'UnitedAirlines': 33, 'fail': 16, 'united': 15, 'customerservice': 12, 'unitedairlines': 10, 'United': 10, 'unfriendlyskies': 9, 'avgeek': 8, 'unitedsucks': 8, 'badservice': 7}\n",
            "{'DestinationDragons': 71, 'fail': 6, 'disappointed': 5, 'southwestairlines': 5, 'B737-700': 5, 'avgeek': 5, 'customerservice': 5, 'destinationdragons': 5, 'SWA': 4, 'notcool': 4}\n",
            "{'usairwaysfail': 25, 'USAirways': 15, 'fail': 14, 'usairways': 12, 'customerservice': 7, 'neveragain': 6, 'usairwayssucks': 6, 'disappointed': 5, 'nothappy': 4, 'badcustomerservice': 4}\n",
            "{'jetblue': 33, 'JetBlue': 8, 'flyingitforward': 7, 'travel': 6, 'Lufthansa': 6, 'fail': 6, 'JVMChat': 5, 'flyfi': 4, 'trueblue': 4, 'jfk': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTzt9Rn1AzHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "95149de0-2ae9-4147-dd8e-96327bb8b77f"
      },
      "source": [
        "#WHICH AIRLINE HAS THE WORST REPUTATION FOR EACH KIND OF COMPLAINT BASED OFF THE CSV DATA\n",
        "#PRIORITISE LATE\n",
        "\n",
        "def count_complaint(complaints):\n",
        "  return {complaint: count for complaint, count in Counter(complaints).most_common(12)}\n",
        "for path in paths:\n",
        "  print(path)\n",
        "  print(count_complaint(import_dataset(path)['negative_reason']))\n",
        "  \n",
        "#Takeaways:\n",
        "#Virgin is the least represented in the dataset however, it has relatively fewer complaints than the others\n",
        "#Delta rarely cancel flights compared to the other large airlines.\n",
        "#US Airways have more customer service issues than neutral or positive tweets about them which is rather alarming\n",
        "#American has far more complaints than it has positive or neutral tweets\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/american.csv\n",
            "{nan: 799, 'Customer Service Issue': 768, 'Late Flight': 249, 'Cancelled Flight': 246, \"Can't Tell\": 198, 'Lost Luggage': 149, 'Flight Booking Problems': 130, 'Bad Flight': 87, 'Flight Attendant Complaints': 87, 'longlines': 34, 'Damaged Luggage': 12}\n",
            "/content/virgin.csv\n",
            "{nan: 323, 'Customer Service Issue': 60, 'Flight Booking Problems': 28, \"Can't Tell\": 22, 'Bad Flight': 19, 'Cancelled Flight': 18, 'Late Flight': 17, 'Lost Luggage': 5, 'Flight Attendant Complaints': 5, 'Damaged Luggage': 4, 'longlines': 3}\n",
            "/content/united.csv\n",
            "{nan: 1189, 'Customer Service Issue': 681, 'Late Flight': 525, \"Can't Tell\": 379, 'Lost Luggage': 269, 'Bad Flight': 216, 'Cancelled Flight': 181, 'Flight Attendant Complaints': 168, 'Flight Booking Problems': 144, 'longlines': 48, 'Damaged Luggage': 22}\n",
            "/content/southwest.csv\n",
            "{nan: 1234, 'Customer Service Issue': 391, 'Cancelled Flight': 162, \"Can't Tell\": 159, 'Late Flight': 152, 'Bad Flight': 90, 'Lost Luggage': 90, 'Flight Booking Problems': 61, 'Flight Attendant Complaints': 38, 'longlines': 29, 'Damaged Luggage': 14}\n",
            "/content/us_airways.csv\n",
            "{'Customer Service Issue': 811, nan: 650, 'Late Flight': 453, \"Can't Tell\": 246, 'Cancelled Flight': 189, 'Lost Luggage': 154, 'Flight Attendant Complaints': 123, 'Flight Booking Problems': 122, 'Bad Flight': 104, 'longlines': 50, 'Damaged Luggage': 11}\n",
            "/content/delta.csv\n",
            "{nan: 1267, 'Late Flight': 269, 'Customer Service Issue': 199, \"Can't Tell\": 186, 'Bad Flight': 64, 'Flight Attendant Complaints': 60, 'Lost Luggage': 57, 'Cancelled Flight': 51, 'Flight Booking Problems': 44, 'longlines': 14, 'Damaged Luggage': 11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRaZf6KUFrJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "52bd4a8b-d542-4d2f-e037-fe6134501884"
      },
      "source": [
        "#FIND OUT IF ANY OF THE DAMAGED LUGGAGE INCIDENTS HAPPENED ON THE SAME UNITED FLIGHT\n",
        "dataset = import_dataset(paths[5]) #CHANGE BETWEEN 0 AND 5 TO SHOW DIFFERENT TWEETS\n",
        "\n",
        "for index, row in enumerate(dataset['negative_reason'], start=0):\n",
        "  if row == 'Damaged Luggage':\n",
        "    print(dataset['name'].loc[index], dataset['text'].loc[index], dataset['creation_time'].loc[index], dataset['location'].loc[index])\n",
        "    print('\\n')\n",
        "\n",
        "#VIRGIN AMERICA ONLY HAS ONE ACTUAL INCIDENT OF LUGGAGE BEING DAMAGED. THEY DON'T NEED TO IMPROVE THIS ASPECT OF THEIR SERVICE\n",
        "#3 OF THE TWEETS ARE FROM THE SAME USER ABOUT THE SAME INCIDENT\n",
        "#THE OTHER TWEET WAS ABOUT WORRYING IF ITEMS WERE GOING TO BE DAMAGED; NOT THAT THEY WERE.\n",
        "\n",
        "#AMERICAN AIR CUSTOMER SERVICES RESPONED TO A USER WHOSE BAG WAS DAMAGED AT STAMFORD CT TO RESOLVE THE ISSUE\n",
        "#DESPITE THIS BEING A NEGATIVE TWEET ACCORING TO ITS SENTIMENT, THE HASHTAG MAKES IT POSITIVE, HENCE THE IMPORTANCE OF HASHTAG ANALYSIS\n",
        "\n",
        "#AMERICAN AIR USER REPORTED THEIR LUGGAGE TO HAVE BEEN STOLEN BY BAGGAGE HANDLERS?\n",
        "#LIKE VIRGIN, THERE AREN'T ACTUALLY THAT MANY CASES OF DAMAGED LUGGAGE. NEARLY HALF OF THE TWEETS ABOUT THIS ISSUE ARE REPLIES.\n",
        "#COMPLAINTS THAT TABLET WAS DAMAGED IS MORE ON THE CUSTOMER STORING A FLAT DEVICE LIKE THAT AT THE TOP OF A SUITCASE.\n",
        "\n",
        "#UNITED DAMAGED LUGGAGE CASES ARE ALL ISOLATED INCIDENTS AT DIFFERENT LOCATIONS HOWEVER, THE TWEETS MOSTLY SAY THAT SOMETHING WAS INDEED DAMAGED.\n",
        "#AGAIN, THERE ARE SOME WHICH ARE CLASSED AS DAMAGED LUGGAGE YET NOTHING HAS DEFINITIVELY BEEN DAMAGED.\n",
        "\n",
        "#SOUTHWEST DOES NOT APPEAR TO RESPOND TO CUSTOMERS DIRECTLY EVEN IF THEY TAG THEM AND SHOW A PHOTO OF THE DAMAGE\n",
        "#SOME OF THE TWEETS ARE INCORRECTLY CLASSIFIED AS DAMAGED LUGGAGE ONCE AGAIN WHEN THEY'RE ACTUALLY ABOUT DAMAGE BEING PREVENTED\n",
        "\n",
        "#MOST OF THE US AIRWAYS TWEETS HAVE BEEN CORRECTLY CLASSIFIED. THERE ARE A FEW REPLIES WHICH CAN BE REMOVED WITH JONATHAN'S REPLY DESTROYER\n",
        "#SOME ARE ABOUT THE BAGGAGE COLLECTION SERVICE HAVING DELAYS WHICH ISN'T A DAMAGE PROBLEM BUT INSTEAD CUSTOMER SERVICE\n",
        "\n",
        "#JETBLUE CUSTOMER SERVICES ON TWITTER ARE INDEED RESPONSIVE IF A USER REPORTS STOLEN BAGS AS SHOWN IN JetBlue.JPG\n",
        "#THESE TWEETS SHOW A PROBLEM WITH NLP: PEOPLE USING 2 INSTEAD OF TWO"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DarthVada_R2D2 @JetBlue - Definitely no note from whoever stole from me. 23/02/2015 19:42 nan\n",
            "\n",
            "\n",
            "edgarsantana @JetBlue I just submitted feedback for you @gripeo. Not a good way 2 handle baggage or customers: http://t.co/F6COpX1Fvj 18/02/2015 17:26 ÜT: 40.96513,-73.872957\n",
            "\n",
            "\n",
            "edgarsantana @JetBlue I had 2 fight 2 get a credit for the value of my bag but I got it. #skytrax #jetblue #corpgreed #nevertakeno http://t.co/6MBVJFlpBM 18/02/2015 16:05 ÜT: 40.96513,-73.872957\n",
            "\n",
            "\n",
            "edgarsantana @JetBlue so why do you put this at the bottom of ur baggage report? For fun? #JetBlue @airlinequality #skytrax http://t.co/tU9JX2jaZN 18/02/2015 15:11 ÜT: 40.96513,-73.872957\n",
            "\n",
            "\n",
            "edgarsantana @JetBlue u now have my gears grinding. The JFK baggage office told me I need to bring the bag back right now if not they will close my claim 18/02/2015 14:54 ÜT: 40.96513,-73.872957\n",
            "\n",
            "\n",
            "edgarsantana @JetBlue U say our safety is our highest priority but that doesn't extend 2 our property? This is totally nuts. http://t.co/xZY7pHKFGR 18/02/2015 14:38 ÜT: 40.96513,-73.872957\n",
            "\n",
            "\n",
            "edgarsantana @JetBlue glad u happy I have my bag but as a traveler I entrusted u w/ my property &amp; u return it damaged &amp; that's the best answer u have? 18/02/2015 14:33 ÜT: 40.96513,-73.872957\n",
            "\n",
            "\n",
            "LisaPal @JetBlue but you guys should know that musicians are very sensitive about the safety of their instruments when flying. For good reason. 18/02/2015 09:58 New Orleans, LA\n",
            "\n",
            "\n",
            "michaelhakimkan @JetBlue ripped my suitcase. I then was yelled at with attitude from Geraldine, your employee at the baggage center.Worst airline= #jetblue 17/02/2015 20:30 nan\n",
            "\n",
            "\n",
            "ShiraJudah @JetBlue @KyleJudah new stroller. The travel credit doesn't help cover the cost of a new stroller. Your crew ruined it and therefore should 17/02/2015 11:48 Boston, MA\n",
            "\n",
            "\n",
            "ShiraJudah @JetBlue @KyleJudah I just spoke to the baggage claim center and they gave me travel credit but will not be responsible for the cost of a 17/02/2015 11:46 Boston, MA\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYR9LPysWhHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Take each emoji and give it a polarity modifier. If it appears in the text, add the modifier to the sentiment score.\n",
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "import csv\n",
        "texts = []\n",
        "sentiments = []\n",
        "results = []\n",
        "def reset_score(score):\n",
        "  if score > 1:\n",
        "    return 1\n",
        "  if score < -1:\n",
        "    return -1\n",
        "  return score  \n",
        "def emoji_based_sentiment(tweets, combined, results):\n",
        "  with open('/content/textblobsentiments.csv','w') as file:\n",
        "    writer = csv.writer(file)\n",
        "    for tweet in tweets['text']:\n",
        "      score = TextBlob(tweet).sentiment[0]\n",
        "      oldscore = score\n",
        "      for record in combined:\n",
        "        if record[0] in tweet:\n",
        "          score += record[1]\n",
        "      score = reset_score(score)\n",
        "      writer.writerow((tweet, oldscore, score))\n",
        "\n",
        "emojis = ['❤', '❤️', '☺', '☺️', '👍', '😡', '😢', '✈', '💜', '✈️', '💺', '🍷', '😊', '👌', '😍', '💕', '🌞', '😃', '😭', '😩', '😎', '🙉', '😁', '❄', '❄️', '👏', '😂', '💗', '🍸', '😒', '👎', '😀', '😄', '😘', '🇺🇸', '👸', '🇸', '🇺', '🇬🇧', '🌏', '🇧', '🇬', '🎀', '😥', '😉', '😱', '✨', '🎉', '🙌', '💤', '😞', '♥', '👋', '✌', '✌️', '🙏', '👿', '😔', '🙅', '🆖', '💩', '✔️', '✔', '🌴', '❌', '✅', '👠', '😜', '😻', '😕', '😈', '😤', '💪', '😫', '💔', '😪', '😣', '😬', '💁', '😋', '😏', '😖', '🌟', '📱', '🍻', '💖', '😅', '💝', '↔', '↔️', '🚫', '😷', '⭐', '❗', '🎵', '🐴', '♥️', '😆', '😑', '🐩', '⤴', '☀', '☀️', '👊', '💯', '😠', '☕', '📲', '👺', '🙈', '💘', '💙', '👉', '🚪', '😳', '😵', '🚶', '🔵', '😐', '👀', '🍅', '🆘', '⛄', '😓', '🎲', '⌚', '🐳', '⤵', '😮', '😲', '😦', '➡', '➡️']\n",
        "scores = [0.25,0.27,0.2,0.2,0.15,-0.2,-0.25,0.05,0.25,0.05,0.02,0.08,0.3,0.15,0.3,0.2,0.19,0.25,-0.3,-0.25,0.15,-0.1,0.27,-0.08,-0.08,0.1,0.05,0.18,0.06,-0.18,-0.2,0.28,0.25,0.16,0.05,0.03,0.00,0.00,0.00,0.05,0.00,0.00,0.04,-0.16,0.14,-0.19,0.09,0.13,0.13,-0.04,-0.21,0.22,0.06,0.07,0.07,0.09,-0.3,-0.14,-0.08,0.00,-0.3,0.2,0.2,0.11,-0.2,0.2,0.05,0.15,0.12,-0.16,-0.28,-0.25,0.15,-0.16,-0.2,0.03,-0.04,-0.07,0.00,0.16,0.04,-0.16,0.24,0.03,0.1,0.25,0.1,0.25,0.0,0.0,-0.1,-0.15,0.22,-0.06,0.05,0.02,0.06,-0.1,0.1,0.0,0.03,0.1,-0.01,0.17,-0.2,0.06,0.06,-0.1,0.05,-0.15,0.2,0.04,0.01,-0.05,-0.08,0.00,0.00,-0.09,-0.05,0.05,-0.14,0.04,-0.15,0.1,-0.1,0.1,0.01,0.05,0.0,0.1,0.05,-0.1,0.00,0.00]\n",
        "combined = list(zip(emojis, scores))\n",
        "\n",
        "tweets = pd.read_csv('/content/Tweets.csv')\n",
        "emoji_based_sentiment(tweets, combined, results)"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}